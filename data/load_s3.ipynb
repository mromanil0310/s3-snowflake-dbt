{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "import boto3\n",
    "import pandas as pd\n",
    "from faker import Faker\n",
    "import random\n",
    "from io import StringIO\n",
    "from datetime import datetime\n",
    "import snowflake.connector\n",
    "from dotenv import load_dotenv\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Initialize Faker and AWS S3 client\n",
    "fake = Faker()\n",
    "s3 = boto3.client('s3')\n",
    "\n",
    "# Load .env\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3 = boto3.client(\n",
    "    \"s3\",\n",
    "    endpoint_url=\"http://localhost:9100\",\n",
    "    aws_access_key_id=\"minioadmin\",\n",
    "    aws_secret_access_key=\"minioadmin\",\n",
    "    region_name=\"us-east-1\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_cdc_order_data(num_rows):\n",
    "    data = []\n",
    "    for _ in range(num_rows):\n",
    "        order = {\n",
    "            'order_id': fake.uuid4(),\n",
    "            'customer_id': fake.uuid4(),\n",
    "            'order_date': fake.date_this_year(),\n",
    "            'status': random.choice(['CREATED', 'SHIPPED', 'DELIVERED', 'CANCELLED']),\n",
    "            'product_id': fake.uuid4(),\n",
    "            'quantity': random.randint(1, 5),\n",
    "            'price': round(random.uniform(10.0, 500.0), 2),\n",
    "            'total_amount': 0.0,  # We'll calculate this next\n",
    "            'cdc_timestamp': datetime.now()   # Simulate CDC timestamp\n",
    "        }\n",
    "        order['total_amount'] = round(order['quantity'] * order['price'], 2)\n",
    "        data.append(order)\n",
    "\n",
    "    # Convert to DataFrame\n",
    "    df = pd.DataFrame(data)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data uploaded to s3://raw/fake_cdc_order_data_12.csv\n"
     ]
    }
   ],
   "source": [
    "# Define S3 bucket and file path\n",
    "bucket_name = 'raw'\n",
    "file_name = 'fake_cdc_order_data_12.csv' #can be parquet, csv etc.\n",
    "num_rows = 150\n",
    "\n",
    "# Function to upload data to S3\n",
    "def upload_to_s3(bucket_name, file_name, df):\n",
    "    csv_buffer = StringIO()\n",
    "    df.to_csv(csv_buffer, index=False)\n",
    "    s3.put_object(Bucket=bucket_name, Key=file_name, Body=csv_buffer.getvalue())\n",
    "    print(f\"Data uploaded to s3://{bucket_name}/{file_name}\")\n",
    "\n",
    "# Generate n rows of fake CDC order data\n",
    "df_cdc_order_data = generate_cdc_order_data(num_rows)\n",
    "\n",
    "# Upload the generated data to S3\n",
    "upload_to_s3(bucket_name, file_name, df_cdc_order_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "s3.download_file(\"raw\", file_name, f\"/tmp/{file_name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Executing: \n",
      "PUT file:///tmp/fake_cdc_order_data_12.csv\n",
      "@DBT_ELT.STAGING.MY_INTERNAL_STAGE\n",
      "AUTO_COMPRESS=TRUE\n",
      "\n"
     ]
    }
   ],
   "source": [
    "sf = {\n",
    "    \"user\": os.getenv(\"SNOWFLAKE_USER\"),\n",
    "    \"password\": os.getenv(\"SNOWFLAKE_PASSWORD\"),\n",
    "    \"account\": os.getenv(\"SNOWFLAKE_ACCOUNT\"),\n",
    "    \"warehouse\": os.getenv(\"SNOWFLAKE_WAREHOUSE\"),\n",
    "    \"database\": os.getenv(\"SNOWFLAKE_DATABASE\"),\n",
    "    \"schema\": os.getenv(\"SNOWFLAKE_SCHEMA\"),\n",
    "}\n",
    "\n",
    "missing = [k for k, v in sf.items() if not v]\n",
    "if missing:\n",
    "    raise ValueError(f\"Missing env vars: {missing}\")\n",
    "\n",
    "conn = snowflake.connector.connect(**sf)\n",
    "cursor = conn.cursor()\n",
    "\n",
    "sql = f\"\"\"\n",
    "PUT file:///tmp/{file_name}\n",
    "@DBT_ELT.STAGING.MY_INTERNAL_STAGE\n",
    "AUTO_COMPRESS=TRUE\n",
    "\"\"\"\n",
    "\n",
    "print(\"Executing:\", sql)\n",
    "cursor.execute(sql)\n",
    "\n",
    "cursor.close()\n",
    "conn.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "notebook_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
